{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cd12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1da001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging training data from current and 2 months earlier\n",
    "data_train = pd.read_csv(\"train_month_3_with_target.csv\")\n",
    "data_train_1 = pd.read_csv(\"train_month_1.csv\")\n",
    "data_train_2 = pd.read_csv(\"train_month_2.csv\")\n",
    "train_1 = pd.merge(data_train, data_train_1, on=\"client_id\", suffixes=(\"\", \"_1\"))\n",
    "train=pd.merge(train_1, data_train_2, on=\"client_id\", suffixes=(\"\", \"_2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f963a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging test data from current and 2 months earlier\n",
    "data_test = pd.read_csv(\"test_month_3.csv\")\n",
    "data_test_1 = pd.read_csv(\"test_month_1.csv\")\n",
    "data_test_2 = pd.read_csv(\"test_month_2.csv\")\n",
    "test_1 = pd.merge(data_test, data_test_1, on=\"client_id\", suffixes=(\"\", \"_1\"))\n",
    "test=pd.merge(test_1, data_test_2, on=\"client_id\", suffixes=(\"\", \"_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb78407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# homebanking_active and has_homebanking are closely related \n",
    "# has 5 types of insurances \n",
    "# has 2 types of  personal loans \n",
    "# has 5 types of accounts (current, savings, pension, 2 starter ones)\n",
    "# balances of 5 types of insurances \n",
    "# outstanding balances of 2 types of  personal loans \n",
    "# balances on 5 types of accounts (current, savings, pension, 2 starter ones)\n",
    "# number of branches /and areas visited in the past month\n",
    "# 2 types customer since (2 NAs)\n",
    "# gender/ birthday / occupation (coded) (NAs)/ self employed\n",
    "# education level (NAs)/ children (NAs) / relationship (NAs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b40fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for relationship lets take a third category (so these will be nominal)\n",
    "#for children take the mode in the class\n",
    "#for education take the mean\n",
    "#for occupation code take the mode in the class\n",
    "#for both customers take the mean in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40c31d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will help to identify columns with the same values\n",
    "###\n",
    "#from itertools import combinations\n",
    "#\n",
    "#[(i, j) for i,j in combinations(x_train, 2) if x_train[i].equals(x_train[j])]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c116b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in the training (70%) and validation set (30%)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train.drop(columns=\"target\"), train['target'], test_size = .3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01244352",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# This function drops the copy columns that have the same values, changes the date to time passed (months for \n",
    "# customer since, and years for age of the customer), then we also add new NA indicator columns, also \n",
    "# target is added in the end\n",
    "def cleaning_tr (data_x, data_y):\n",
    "    #DROPPING COPIES\n",
    "    data_x.drop(columns=[\"customer_since_all_1\", \"customer_since_all_2\", \n",
    "                        \"customer_since_bank_1\", \"customer_since_bank_2\", \n",
    "                        \"customer_gender_1\", \"customer_gender_2\",\n",
    "                        \"customer_birth_date_1\", \"customer_birth_date_2\", \n",
    "                        \"customer_postal_code_1\", \"customer_postal_code_2\", \n",
    "                        \"customer_occupation_code_1\", \"customer_occupation_code_2\",\n",
    "                        \"customer_education_1\", \"customer_education_2\", \n",
    "                       ], inplace=True)\n",
    "    #DATE FORMATTING\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        data_x[column]=data_x[column]+\"-01\"\n",
    "        data_x[column]=pd.to_datetime(data_x[column], infer_datetime_format=True)\n",
    "    t=data_x.index\n",
    "    l=data_x.shape[0]\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        a={'today':date.today()}\n",
    "        x=pd.DataFrame(a, index=[0])\n",
    "        y=pd.concat([x]*l, ignore_index=True)\n",
    "        y.index=t\n",
    "        z=pd.to_datetime(y[\"today\"], infer_datetime_format=True)\n",
    "        data_x[column]= (z-data_x[column])/np.timedelta64(1,'M')\n",
    "    data_x[\"customer_birth_date\"]=data_x[\"customer_birth_date\"]/12\n",
    "    #MAKING IS NA COLUMN\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \n",
    "               \"customer_occupation_code\", \"customer_education\", \n",
    "               \"customer_children\", \"customer_relationship\", \n",
    "               \"customer_children_1\", \"customer_relationship_1\",\n",
    "               \"customer_children_2\", \"customer_relationship_2\"]:\n",
    "        data_x[column+\"_is_na\"]=data_x[column].isna().apply(lambda x: 0 if x==0 else 1)\n",
    "        \n",
    "    data_x[\"target\"]=data_y\n",
    "    \n",
    "    return data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28f57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean=cleaning_tr (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91962517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes new data out of clean data where we work on customer_relationship and customer_children\n",
    "# we then drop target and client_id\n",
    "def nahandle_tr(data_x):\n",
    "    #FILLING IN NA COLUMNS\n",
    "    import copy\n",
    "    #we need deepcopy as we need the input of the function at a later point\n",
    "    new=copy.deepcopy(data_x)\n",
    "\n",
    "    #customer_relationship NA is given its own level\n",
    "    new[\"customer_relationship\"].fillna(value=\"unknown\", inplace=True)\n",
    "    new[\"customer_relationship_1\"].fillna(value=\"unknown\", inplace=True)\n",
    "    new[\"customer_relationship_2\"].fillna(value=\"unknown\", inplace=True)\n",
    "    \n",
    "    f = lambda x: x.mean() if np.issubdtype(x.dtype, np.number) else x.mode().iloc[0]\n",
    "    new = new.fillna(new.groupby('target').transform(f))\n",
    "    \n",
    "    #FINAL TOUCH\n",
    "    new=new.drop(columns=[\"target\",\"client_id\"])\n",
    "    \n",
    "    return new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aeb47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_handled=nahandle_tr(x_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7328244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we only havw to encode customer relationships and drop the original columns\n",
    "def encoding(data_x):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship']]).toarray())\n",
    "    encoder_df.columns=[\"rel_a\", \"rel_b\", \"rel_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_1']]).toarray())\n",
    "    encoder_df.columns=[\"rel1_a\", \"rel1_b\", \"rel1_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_2']]).toarray())\n",
    "    encoder_df.columns=[\"rel2_a\", \"rel2_b\", \"rel2_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    \n",
    "    #customer_childer are given numbers indicating how much care needed for kids\n",
    "    region_dictionary = {'no': 0, 'onebaby' : 1, 'preschool':2, 'young':4, 'adolescent':5, 'grownup':6, 'mature':7, 'yes': 3}\n",
    "    data_x['customer_children'] = data_x['customer_children'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_1'] = data_x['customer_children_1'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_2'] = data_x['customer_children_2'].apply(lambda x: region_dictionary[x])\n",
    "    \n",
    "    #FINAL TOUCH\n",
    "    data_x=data_x.drop(columns=['customer_relationship', 'customer_relationship_1', 'customer_relationship_2'])\n",
    "    \n",
    "    return data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e86cba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=encoding(x_train_handled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91376d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=pd.DataFrame(columns=[\"customer_children\", \"customer_children_1\", \"customer_children_2\",\n",
    "                          \"customer_relationship\", \"customer_relationship_1\", \"customer_relationship_2\",\n",
    "                          \"customer_since_all\", \"customer_since_bank\", \n",
    "                          \"customer_occupation_code\", \"customer_education\"], index=[0,1])\n",
    "\n",
    "for col in val.columns:\n",
    "    val[col][0]=x_train_handled[col][x_train_handled[(x_train_clean[col].isna()) & (x_train_clean['target']==0)].index[0]]\n",
    "    val[col][1]=x_train_handled[col][x_train_handled[(x_train_clean[col].isna()) & (x_train_clean['target']==1)].index[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2267b38",
   "metadata": {},
   "source": [
    "## At this point we have x_train that has every column as numeric and without the target AND the values we need to impute, we will now proceed to cleaning/na_handling for the test/validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0330b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function drops the copy columns that have the same values, changes the date to time passed (months for \n",
    "# customer since, and years for age of the customer), then we also add new NA indicator columns\n",
    "def cleaning_val (data):\n",
    "    import copy\n",
    "    data_x=copy.deepcopy(data)\n",
    "    #DROPPING COPIES\n",
    "    data_x.drop(columns=[\"customer_since_all_1\", \"customer_since_all_2\", \n",
    "                        \"customer_since_bank_1\", \"customer_since_bank_2\", \n",
    "                        \"customer_gender_1\", \"customer_gender_2\",\n",
    "                        \"customer_birth_date_1\", \"customer_birth_date_2\", \n",
    "                        \"customer_postal_code_1\", \"customer_postal_code_2\", \n",
    "                        \"customer_occupation_code_1\", \"customer_occupation_code_2\",\n",
    "                        \"customer_education_1\", \"customer_education_2\", \n",
    "                       ], inplace=True)\n",
    "    #DATE FORMATTING\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        data_x[column]=data_x[column]+\"-01\"\n",
    "        data_x[column]=pd.to_datetime(data_x[column], infer_datetime_format=True)\n",
    "    t=data_x.index\n",
    "    l=data_x.shape[0]\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        a={'today':date.today()}\n",
    "        x=pd.DataFrame(a, index=[0])\n",
    "        y=pd.concat([x]*l, ignore_index=True)\n",
    "        y.index=t\n",
    "        z=pd.to_datetime(y[\"today\"], infer_datetime_format=True)\n",
    "        data_x[column]= (z-data_x[column])/np.timedelta64(1,'M')\n",
    "    data_x[\"customer_birth_date\"]=data_x[\"customer_birth_date\"]/12\n",
    "    #MAKING IS NA COLUMN\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \n",
    "               \"customer_occupation_code\", \"customer_education\", \n",
    "               \"customer_children\", \"customer_relationship\", \n",
    "               \"customer_children_1\", \"customer_relationship_1\",\n",
    "               \"customer_children_2\", \"customer_relationship_2\"]:\n",
    "        data_x[column+\"_is_na\"]=data_x[column].isna().apply(lambda x: 0 if x==0 else 1)\n",
    "    \n",
    "    return data_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46164bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes new data out of clean data where we work on customer_relationship and customer_children\n",
    "# we then drop target and client_id\n",
    "def nahandle_val(data):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    import copy\n",
    "    data_x=copy.deepcopy(data)\n",
    "    \n",
    "    data_x=data_x.drop(columns=[\"client_id\"])\n",
    "    #FILLING IN NA COLUMNS\n",
    "    \n",
    "    for col in val.columns:\n",
    "        #get dtype for column\n",
    "        dt = data_x[col].dtype \n",
    "        #check if it is a number\n",
    "        if dt == np.int64 or dt==np.float64:\n",
    "            data_x[col].fillna(val[col].mean(), inplace=True)\n",
    "        else:\n",
    "            data_x[col].fillna(val[col].mode().iloc[0], inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b1b0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we only havw to encode customer relationships and drop the original columns\n",
    "def encoding(data):\n",
    "    import copy\n",
    "    data_x=copy.deepcopy(data)\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship']]).toarray())\n",
    "    encoder_df.columns=[\"rel_a\", \"rel_b\", \"rel_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_1']]).toarray())\n",
    "    encoder_df.columns=[\"rel1_a\", \"rel1_b\", \"rel1_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_2']]).toarray())\n",
    "    encoder_df.columns=[\"rel2_a\", \"rel2_b\", \"rel2_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    \n",
    "    #customer_childer are given numbers indicating how much care needed for kids\n",
    "    region_dictionary = {'no': 0, 'onebaby' : 1, 'preschool':2, 'young':4, 'adolescent':5, 'grownup':6, 'mature':7, 'yes': 3}\n",
    "    data_x['customer_children'] = data_x['customer_children'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_1'] = data_x['customer_children_1'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_2'] = data_x['customer_children_2'].apply(lambda x: region_dictionary[x])\n",
    "    \n",
    "    #FINAL TOUCH\n",
    "    data_x=data_x.drop(columns=['customer_relationship', 'customer_relationship_1', 'customer_relationship_2'])\n",
    "    \n",
    "    return data_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1301b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean=cleaning_val(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9506b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "handled=nahandle_val(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3daeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=encoding(handled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741c0d6",
   "metadata": {},
   "source": [
    "## Now we have the data for val/test it is time to run some tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d4ffa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "009f58ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15917  2603]\n",
      " [  360   230]]\n"
     ]
    }
   ],
   "source": [
    "# bagged decision trees with random undersampling for imbalanced classification\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "# define model\n",
    "model = BalancedBaggingClassifier(n_estimators=50)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5183070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18520     0]\n",
      " [  590     0]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for imbalanced classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define model\n",
    "model = RandomForestClassifier(n_estimators=50, class_weight='balanced')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd69d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18520     0]\n",
      " [  590     0]]\n"
     ]
    }
   ],
   "source": [
    "# bootstrap class balanced random forest for imbalanced classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define model\n",
    "model = RandomForestClassifier(n_estimators=50, class_weight='balanced')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0e57e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14601  3919]\n",
      " [  288   302]]\n"
     ]
    }
   ],
   "source": [
    "# random forest with random undersampling for imbalanced classification\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# define model\n",
    "model = BalancedRandomForestClassifier(n_estimators=50)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c29b2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14444  4076]\n",
      " [  292   298]]\n"
     ]
    }
   ],
   "source": [
    "# easy ensemble for imbalanced classification\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "# define model\n",
    "model = EasyEnsembleClassifier(n_estimators=20)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24084ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
