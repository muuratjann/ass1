{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cd12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas_profiling import ProfileReport\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1da001",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train_month_3_with_target.csv\")\n",
    "data_train_1 = pd.read_csv(\"train_month_1.csv\")\n",
    "data_train_2 = pd.read_csv(\"train_month_2.csv\")\n",
    "train_1 = pd.merge(data_train, data_train_1, on=\"client_id\", suffixes=(\"\", \"_1\"))\n",
    "train=pd.merge(train_1, data_train_2, on=\"client_id\", suffixes=(\"\", \"_2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f963a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test_month_3.csv\")\n",
    "data_test_1 = pd.read_csv(\"test_month_1.csv\")\n",
    "data_test_2 = pd.read_csv(\"test_month_2.csv\")\n",
    "test_1 = pd.merge(data_test, data_test_1, on=\"client_id\", suffixes=(\"\", \"_1\"))\n",
    "test=pd.merge(test_1, data_test_2, on=\"client_id\", suffixes=(\"\", \"_2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c116b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in the training (70%) and testing set (30%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.drop(columns=\"target\"), train['target'], test_size = .3, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01244352",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cleaning_tr (data_x, data_y):\n",
    "    data_x.drop(columns=[\"customer_since_all_1\", \"customer_since_all_2\", \n",
    "                        \"customer_since_bank_1\", \"customer_since_bank_2\", \n",
    "                        \"customer_gender_1\", \"customer_gender_2\",\n",
    "                        \"customer_birth_date_1\", \"customer_birth_date_2\", \n",
    "                        \"customer_postal_code_1\", \"customer_postal_code_2\", \n",
    "                        \"customer_occupation_code_1\", \"customer_occupation_code_2\",\n",
    "                        \"customer_education_1\", \"customer_education_2\", \n",
    "                       ], inplace=True)\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        data_x[column]=data_x[column]+\"-01\"\n",
    "        data_x[column]=pd.to_datetime(data_x[column], infer_datetime_format=True)\n",
    "    t=data_x.index\n",
    "    l=data_x.shape[0]\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        a={'today':date.today()}\n",
    "        x=pd.DataFrame(a, index=[0])\n",
    "        y=pd.concat([x]*l, ignore_index=True)\n",
    "        y.index=t\n",
    "        z=pd.to_datetime(y[\"today\"], infer_datetime_format=True)\n",
    "        data_x[column]= (z-data_x[column])/np.timedelta64(1,'M')\n",
    "    data_x[\"customer_birth_date\"]=data_x[\"customer_birth_date\"]/12\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \n",
    "               \"customer_occupation_code\", \"customer_education\", \n",
    "               \"customer_children\", \"customer_relationship\"]:\n",
    "        data_x[column+\"_is_na\"]=data_x[column].isna().apply(lambda x: 0 if x==0 else 1)\n",
    "    data_x[\"target\"]=data_y\n",
    "    \n",
    "    data_x[\"customer_relationship\"].fillna(value=\"unknown\", inplace=True)\n",
    "    data_x[\"customer_relationship_1\"].fillna(value=\"unknown\", inplace=True)\n",
    "    data_x[\"customer_relationship_2\"].fillna(value=\"unknown\", inplace=True)\n",
    "    \n",
    "    f = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else x.mode().iloc[0]\n",
    "    data_x = data_x.fillna(data_x.groupby('target').transform(f))\n",
    "\n",
    "    data_x=data_x.drop(columns=[\"target\",\"client_id\"])\n",
    "    \n",
    "    region_dictionary = {'no': 0, 'onebaby' : 2, 'preschool':3, 'young':5, 'adolescent':6, 'grownup':7, 'mature':8, 'yes': 4}\n",
    "    data_x['customer_children'] = data_x['customer_children'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_1'] = data_x['customer_children_1'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_2'] = data_x['customer_children_2'].apply(lambda x: region_dictionary[x])\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship']]).toarray())\n",
    "    encoder_df.columns=[\"rel_a\", \"rel_b\", \"rel_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_1']]).toarray())\n",
    "    encoder_df.columns=[\"rel1_a\", \"rel1_b\", \"rel1_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_2']]).toarray())\n",
    "    encoder_df.columns=[\"rel2_a\", \"rel2_b\", \"rel2_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "\n",
    "    data_x=data_x.drop(columns=['customer_relationship', 'customer_relationship_1', 'customer_relationship_2'])\n",
    "    \n",
    "    return data_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16601c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_tes (data_x, data_y):\n",
    "    data_x.drop(columns=[\"customer_since_all_1\", \"customer_since_all_2\", \n",
    "                        \"customer_since_bank_1\", \"customer_since_bank_2\", \n",
    "                        \"customer_gender_1\", \"customer_gender_2\",\n",
    "                        \"customer_birth_date_1\", \"customer_birth_date_2\", \n",
    "                        \"customer_postal_code_1\", \"customer_postal_code_2\", \n",
    "                        \"customer_occupation_code_1\", \"customer_occupation_code_2\",\n",
    "                        \"customer_education_1\", \"customer_education_2\", \n",
    "                       ], inplace=True)\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        data_x[column]=data_x[column]+\"-01\"\n",
    "        data_x[column]=pd.to_datetime(data_x[column], infer_datetime_format=True)\n",
    "    t=data_x.index\n",
    "    l=data_x.shape[0]\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "        a={'today':date.today()}\n",
    "        x=pd.DataFrame(a, index=[0])\n",
    "        y=pd.concat([x]*l, ignore_index=True)\n",
    "        y.index=t\n",
    "        z=pd.to_datetime(y[\"today\"], infer_datetime_format=True)\n",
    "        data_x[column]= (z-data_x[column])/np.timedelta64(1,'M')\n",
    "    data_x[\"customer_birth_date\"]=data_x[\"customer_birth_date\"]/12\n",
    "    for column in [\"customer_since_all\", \"customer_since_bank\", \n",
    "               \"customer_occupation_code\", \"customer_education\", \n",
    "               \"customer_children\", \"customer_relationship\"]:\n",
    "        data_x[column+\"_is_na\"]=data_x[column].isna().apply(lambda x: 0 if x==0 else 1)\n",
    "        \n",
    "    x_train[\"target\"]=y_train\n",
    "    \n",
    "    data_x[\"customer_relationship\"].fillna(value=\"unknown\", inplace=True)\n",
    "    data_x[\"customer_relationship_1\"].fillna(value=\"unknown\", inplace=True)\n",
    "    data_x[\"customer_relationship_2\"].fillna(value=\"unknown\", inplace=True)\n",
    "    \n",
    "    f = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else x.mode().iloc[0]\n",
    "    data_x = data_x.fillna(x_train.groupby('target').transform(f))\n",
    "\n",
    "    data_x=data_x.drop(columns=[\"client_id\"])\n",
    "    \n",
    "    region_dictionary = {'no': 0, 'onebaby' : 2, 'preschool':3, 'young':5, 'adolescent':6, 'grownup':7, 'mature':8, 'yes': 4}\n",
    "    data_x['customer_children'] = data_x['customer_children'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_1'] = data_x['customer_children_1'].apply(lambda x: region_dictionary[x])\n",
    "    data_x['customer_children_2'] = data_x['customer_children_2'].apply(lambda x: region_dictionary[x])\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship']]).toarray())\n",
    "    encoder_df.columns=[\"rel_a\", \"rel_b\", \"rel_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_1']]).toarray())\n",
    "    encoder_df.columns=[\"rel1_a\", \"rel1_b\", \"rel1_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(data_x[['customer_relationship_2']]).toarray())\n",
    "    encoder_df.columns=[\"rel2_a\", \"rel2_b\", \"rel2_c\"]\n",
    "    encoder_df.index=data_x.index\n",
    "    data_x=data_x.join(encoder_df)\n",
    "\n",
    "    data_x=data_x.drop(columns=['customer_relationship', 'customer_relationship_1', 'customer_relationship_2'])\n",
    "    \n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d67aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr=cleaning_tr(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839bb602",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6j/49k_8t5j4s598_k9my5p11f00000gn/T/ipykernel_4942/4223591050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_te\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcleaning_tes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6j/49k_8t5j4s598_k9my5p11f00000gn/T/ipykernel_4942/3220825013.py\u001b[0m in \u001b[0;36mcleaning_tes\u001b[0;34m(data_x, data_y)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mregion_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'onebaby'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preschool'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'young'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adolescent'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grownup'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/6j/49k_8t5j4s598_k9my5p11f00000gn/T/ipykernel_4942/3220825013.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mregion_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'onebaby'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preschool'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'young'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adolescent'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grownup'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_children_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregion_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "x_te=cleaning_tes(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy ensemble for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "# define model\n",
    "model = EasyEnsembleClassifier(n_estimators=100)\n",
    "model.fit(x_tr, y_train)\n",
    "y_pred = model.predict(x_te)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5183070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# define model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(x_tr, y_train)\n",
    "y_pred = model.predict(x_te)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6f871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac9a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5383d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e954571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af0ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9001dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140a75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5569171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b778d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32ba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddcdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7ad7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e64055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc3ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.sum(train.isna(), axis=0)+np.sum(test.isna(), axis=0)>0)\n",
    "#there is no problem of appearning NAs in other sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated variables. We could exclude those variables once we start building the model or we can use\n",
    "#LASSO or elastic net so that these ones are removed, we will see\n",
    "threshold = 0.3\n",
    "\n",
    "def high_cor_function(df):\n",
    "    cor = df.corr()\n",
    "    corrm = np.corrcoef(df.transpose())\n",
    "    corr = corrm - np.diagflat(corrm.diagonal())\n",
    "    print(\"max corr:\",corr.max(), \", min corr: \", corr.min())\n",
    "    c1 = cor.stack().sort_values(ascending=False).drop_duplicates()\n",
    "    high_cor = c1[c1.values!=1]    \n",
    "    thresh = threshold \n",
    "    display(high_cor[high_cor<thresh])\n",
    "  \n",
    "high_cor_function(x_train.select_dtypes(exclude=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data_train, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"Profiling.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb78407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# homebanking_active and has_homebanking are closely related \n",
    "# has 5 types of insurances \n",
    "# has 2 types of  personal loans \n",
    "# has 5 types of accounts (current, savings, pension, 2 starter ones)\n",
    "# balances of 5 types of insurances \n",
    "# outstanding balances of 2 types of  personal loans \n",
    "# balances on 5 types of accounts (current, savings, pension, 2 starter ones)\n",
    "# number of branches /and areas visited in the past month\n",
    "# 2 types customer since (2 NAs)\n",
    "# gender/ birthday / occupation (coded) (NAs)/ self employed\n",
    "# education level (NAs)/ children (NAs) / relationship (NAs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6355487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in the training set we are only given the datapoints with the stable account for (-3,+3) \n",
    "# but the test set contains all types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46f7ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c31d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "[(i, j) for i,j in combinations(x_train, 2) if x_train[i].equals(x_train[j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39783f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "    x_train[column]=x_train[column]+\"-01\"\n",
    "    x_train[column]=pd.to_datetime(x_train[column], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c52d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "t=x_train.index\n",
    "l=x_train.shape[0]\n",
    "for column in [\"customer_since_all\", \"customer_since_bank\", \"customer_birth_date\"]:\n",
    "    a={'today':date.today()}\n",
    "    x=pd.DataFrame(a, index=[0])\n",
    "    y=pd.concat([x]*l, ignore_index=True)\n",
    "    y.index=t\n",
    "    z=pd.to_datetime(y[\"today\"], infer_datetime_format=True)\n",
    "    x_train[column]= (z-x_train[column])/np.timedelta64(1,'M')\n",
    "x_train[\"customer_birth_date\"]=x_train[\"customer_birth_date\"]/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "plt.scatter(x_train[\"customer_birth_date\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b40fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for relationship lets take a third category (so these will be nominal)\n",
    "#for children take the mode in the class\n",
    "#for education take the mean\n",
    "#for occupation code take the mode in the class\n",
    "# for both customers take the mean in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12253a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"customer_since_all\", \"customer_since_bank\", \n",
    "               \"customer_occupation_code\", \"customer_education\", \n",
    "               \"customer_children\", \"customer_relationship\"]:\n",
    "    x_train[column+\"_is_na\"]=x_train[column].isna().apply(lambda x: 0 if x==0 else 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69180b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[\"target\"]=y_train\n",
    "f = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else x.mode().iloc[0]\n",
    "x_train = x_train.fillna(x_train.groupby('target').transform(f))\n",
    "\n",
    "x_train[\"customer_relationship\"].fillna(value=\"unknown\", inplace=True)\n",
    "x_train[\"customer_relationship_1\"].fillna(value=\"unknown\", inplace=True)\n",
    "x_train[\"customer_relationship_2\"].fillna(value=\"unknown\", inplace=True)\n",
    "\n",
    "x_train=x_train.drop(columns=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb0197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b68d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
